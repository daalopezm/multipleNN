{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import imageio  # Import the imageio library\n",
    "\n",
    "# Step 1: Generate a synthetic dataset\n",
    "#X, y = make_circles(n_samples=200, factor=0.5, noise=0.1, random_state=42)\n",
    "X, y = make_moons(n_samples=200, noise=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Step 2: Define the Polynomial Kernel Function using the intensity profile\n",
    "comblines = 6\n",
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        # Initialize k as a trainable parameter with the same size as C\n",
    "        self.k = nn.Parameter(torch.randn(comblines, dtype=torch.float, device='cpu'))\n",
    "\n",
    "    def forward(self, C, z=2):\n",
    "        return self.compute_intensity(self.k, C, z)\n",
    "\n",
    "    def compute_intensity(self, phases, coefficients, z):\n",
    "        N = coefficients.size(1)\n",
    "\n",
    "        # Prepend NaN to coefficients and phases\n",
    "        nan_tensor = torch.full((coefficients.size(0), 1), float('nan'), dtype=coefficients.dtype, device=coefficients.device)\n",
    "        C = torch.cat((nan_tensor, coefficients), dim=1)\n",
    "\n",
    "        k = torch.cat((torch.tensor([float('nan')], dtype=phases.dtype, device=phases.device), phases))\n",
    "\n",
    "        # Preallocate intensity tensor\n",
    "        intensity = torch.zeros((coefficients.size(0), 2 * N + 1), dtype=torch.float, device=C.device)\n",
    "\n",
    "        # Use vectorized operations where possible\n",
    "        m_range = [torch.full((N-1, N-1), i, device=C.device) for i in torch.arange(2, 2 * N + 1)]\n",
    "        # Separate odd and even tensors based on the integer value inside the tensor\n",
    "        odd_m = [m for m in m_range if m[0, 0].item() % 2 == 1]\n",
    "        even_m = [m for m in m_range if m[0, 0].item() % 2 == 0]\n",
    "\n",
    "        js, ls = torch.meshgrid(torch.arange(1, N, device=C.device), torch.arange(1, N, device=C.device), indexing='ij')\n",
    "        for m in odd_m:\n",
    "\n",
    "            valid_indices = (0 < m - js) & (m - js <= N) & (0 < m - ls) & (m - ls <= N)\n",
    "\n",
    "            j, l, m = js[valid_indices], ls[valid_indices], m[valid_indices]\n",
    "\n",
    "            term = 4 * C[:, j] * C[:, m - j] * C[:, l] * C[:, m - l] * torch.exp(1j * (k[j] + k[m - j] - k[l] - k[m - l]) * z)\n",
    "            intensity[:, m[0]] = term.sum(dim=1)\n",
    "            #torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")\n",
    "\n",
    "        for m in even_m:\n",
    "            if m[0, 0] == 2 or m[0, 0] == 2 * N:\n",
    "                intensity[:, m[0, 0]] = C[:, m[0, 0] // 2] ** 4\n",
    "            else:\n",
    "                valid_indices = (0 < m - js) & (m - js <= N) & (0 < m - ls) & (m - ls <= N)\n",
    "\n",
    "                j, l, m = js[valid_indices], ls[valid_indices], m[valid_indices]\n",
    "\n",
    "                exp_term = torch.exp(1j * (k[j] + k[m - j]) * z)\n",
    "                middle_term = C[:, m // 2] ** 2 * torch.exp(1j * 2 * k[m // 2] * z)\n",
    "\n",
    "                term1 = (2 * C[:, j] * C[:, m - j] * exp_term + middle_term).sum(dim=1)\n",
    "                term2 = (2 * C[:, l] * C[:, m - l] * exp_term.conj() + middle_term.conj()).sum(dim=1)\n",
    "\n",
    "                intensity[:, m[0]] = (term1 * term2).real\n",
    "\n",
    "        return torch.abs(intensity[:, 2:2 * N + 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6931\n",
      "Epoch [2/100], Loss: 9.8430\n",
      "Epoch [3/100], Loss: 5.5938\n",
      "Epoch [4/100], Loss: 1.6411\n",
      "Epoch [5/100], Loss: 2.4689\n",
      "Epoch [6/100], Loss: 3.5072\n",
      "Epoch [7/100], Loss: 3.3980\n",
      "Epoch [8/100], Loss: 2.7037\n",
      "Epoch [9/100], Loss: 1.9035\n",
      "Epoch [10/100], Loss: 1.3142\n",
      "Epoch [11/100], Loss: 1.1005\n",
      "Epoch [12/100], Loss: 1.3385\n",
      "Epoch [13/100], Loss: 1.7462\n",
      "Epoch [14/100], Loss: 1.6377\n",
      "Epoch [15/100], Loss: 1.2298\n",
      "Epoch [16/100], Loss: 0.8843\n",
      "Epoch [17/100], Loss: 0.7702\n",
      "Epoch [18/100], Loss: 0.8052\n",
      "Epoch [19/100], Loss: 0.8694\n",
      "Epoch [20/100], Loss: 0.8721\n",
      "Epoch [21/100], Loss: 0.7783\n",
      "Epoch [22/100], Loss: 0.6122\n",
      "Epoch [23/100], Loss: 0.4566\n",
      "Epoch [24/100], Loss: 0.4199\n",
      "Epoch [25/100], Loss: 0.4761\n",
      "Epoch [26/100], Loss: 0.4688\n",
      "Epoch [27/100], Loss: 0.3759\n",
      "Epoch [28/100], Loss: 0.8820\n",
      "Epoch [29/100], Loss: 0.4431\n",
      "Epoch [30/100], Loss: 0.6617\n",
      "Epoch [31/100], Loss: 0.7165\n",
      "Epoch [32/100], Loss: 0.6716\n",
      "Epoch [33/100], Loss: 0.6599\n",
      "Epoch [34/100], Loss: 0.7400\n",
      "Epoch [35/100], Loss: 0.8620\n",
      "Epoch [36/100], Loss: 0.9538\n",
      "Epoch [37/100], Loss: 0.9816\n",
      "Epoch [38/100], Loss: 0.9478\n",
      "Epoch [39/100], Loss: 0.8799\n",
      "Epoch [40/100], Loss: 0.8238\n",
      "Epoch [41/100], Loss: 0.8082\n",
      "Epoch [42/100], Loss: 0.8170\n",
      "Epoch [43/100], Loss: 0.8003\n",
      "Epoch [44/100], Loss: 0.7293\n",
      "Epoch [45/100], Loss: 0.6227\n",
      "Epoch [46/100], Loss: 0.5272\n",
      "Epoch [47/100], Loss: 0.4759\n",
      "Epoch [48/100], Loss: 0.4417\n",
      "Epoch [49/100], Loss: 0.3817\n",
      "Epoch [50/100], Loss: 0.2944\n",
      "Epoch [51/100], Loss: 0.2166\n",
      "Epoch [52/100], Loss: 0.1783\n",
      "Epoch [53/100], Loss: 0.1644\n",
      "Epoch [54/100], Loss: 0.1480\n",
      "Epoch [55/100], Loss: 0.1217\n",
      "Epoch [56/100], Loss: 0.1105\n",
      "Epoch [57/100], Loss: 0.1275\n",
      "Epoch [58/100], Loss: 0.1436\n",
      "Epoch [59/100], Loss: 0.1363\n",
      "Epoch [60/100], Loss: 0.1212\n",
      "Epoch [61/100], Loss: 0.1220\n",
      "Epoch [62/100], Loss: 0.1298\n",
      "Epoch [63/100], Loss: 0.1179\n",
      "Epoch [64/100], Loss: 0.0970\n",
      "Epoch [65/100], Loss: 0.0895\n",
      "Epoch [66/100], Loss: 0.0887\n",
      "Epoch [67/100], Loss: 0.0789\n",
      "Epoch [68/100], Loss: 0.0647\n",
      "Epoch [69/100], Loss: 0.0602\n",
      "Epoch [70/100], Loss: 0.0630\n",
      "Epoch [71/100], Loss: 0.0611\n",
      "Epoch [72/100], Loss: 0.0558\n",
      "Epoch [73/100], Loss: 0.0560\n",
      "Epoch [74/100], Loss: 0.0605\n",
      "Epoch [75/100], Loss: 0.0609\n",
      "Epoch [76/100], Loss: 0.0579\n",
      "Epoch [77/100], Loss: 0.0583\n",
      "Epoch [78/100], Loss: 0.0611\n",
      "Epoch [79/100], Loss: 0.0607\n",
      "Epoch [80/100], Loss: 0.0581\n",
      "Epoch [81/100], Loss: 0.0581\n",
      "Epoch [82/100], Loss: 0.0595\n",
      "Epoch [83/100], Loss: 0.0581\n",
      "Epoch [84/100], Loss: 0.0560\n",
      "Epoch [85/100], Loss: 0.0563\n",
      "Epoch [86/100], Loss: 0.0566\n",
      "Epoch [87/100], Loss: 0.0550\n",
      "Epoch [88/100], Loss: 0.0538\n",
      "Epoch [89/100], Loss: 0.0541\n",
      "Epoch [90/100], Loss: 0.0537\n",
      "Epoch [91/100], Loss: 0.0522\n",
      "Epoch [92/100], Loss: 0.0518\n",
      "Epoch [93/100], Loss: 0.0518\n",
      "Epoch [94/100], Loss: 0.0510\n",
      "Epoch [95/100], Loss: 0.0502\n",
      "Epoch [96/100], Loss: 0.0501\n",
      "Epoch [97/100], Loss: 0.0500\n",
      "Epoch [98/100], Loss: 0.0493\n",
      "Epoch [99/100], Loss: 0.0490\n",
      "Epoch [100/100], Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalop\\AppData\\Local\\Temp\\ipykernel_8456\\764500954.py:78: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f'./Boundary_Physical_Kernel_images/plot_epoch_{epoch}.png'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "# Original input dimension\n",
    "input_dim = X_train.size(1)\n",
    "\n",
    "# Desired higher dimension (replace with your desired value)\n",
    "hidden_dim = comblines  # e.g., hidden_dim = 10\n",
    "\n",
    "# Step 3: Create a Model\n",
    "class ClassifierNNWithCustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifierNNWithCustomLayer, self).__init__()\n",
    "\n",
    "        # Custom layer \n",
    "        self.custom_layer = CustomLayer() \n",
    "        self.alpha = nn.Parameter(torch.zeros(2*hidden_dim-1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))  # Initialize the bias term\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Create a tensor of 1's with the same batch size as x, but with one additional dimension\n",
    "        ones = torch.ones(x.size(0), 1)  # Shape: (batch_size, 1)\n",
    "        # Concatenate the ones at the beginning of the input tensor along dimension 1\n",
    "        x = torch.cat((ones, ones, x, ones, ones), dim=1)  # Concatenate [1, x_1, y_1, 1]\n",
    "        x = self.custom_layer(x)  # Apply the custom layer\n",
    "        x = torch.matmul(x, self.alpha)+self.bias\n",
    "        return x\n",
    "\n",
    "# Step 4: Train the Model and Visualize\n",
    "model = ClassifierNNWithCustomLayer()\n",
    "optimizer = optim.Adam([model.custom_layer.k, model.alpha, model.bias], lr=0.02)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss with logits\n",
    "\n",
    "# Convert y_train to have values 0 and 1 for binary classification\n",
    "y_train_binary = (y_train > 0).float()\n",
    "\n",
    "# Function to plot decision boundary\n",
    "def plot_decision_boundary(X, y, model, epoch):\n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32)\n",
    "\n",
    "    # Predict the function value for the whole grid\n",
    "    with torch.no_grad():\n",
    "        Z = model(grid_tensor)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Spectral)\n",
    "    plt.title(f'Epoch {epoch}')\n",
    "    plt.savefig(f'./Boundary_Physical_Kernel_images/plot_epoch_{epoch}.png')  # Save the figure\n",
    "    plt.close()\n",
    "\n",
    "interval_images = 1\n",
    "\n",
    "# Training loop with visualization\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train_binary)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Plot the decision boundary every 100 epochs\n",
    "    if (epoch + 1) % interval_images  == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "        plot_decision_boundary(X_train.numpy(), y_train.numpy(), model, epoch+1)\n",
    "\n",
    "\n",
    "# Convert saved images to a GIF\n",
    "images = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    if (epoch) % interval_images  == 0:\n",
    "        images.append(imageio.imread(f'./Boundary_Physical_Kernel_images/plot_epoch_{epoch}.png'))\n",
    "imageio.mimsave('./Boundary_Physical_Kernel_images/decision_boundary_evolution.gif', images, fps=5)\n",
    "\n",
    "# Final evaluation on test data\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "\n",
    "# Convert back to NumPy for scikit-learn metrics\n",
    "y_pred_class = y_pred_class.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "\n",
    "# Transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Download and load the test dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Step 2: Define the Custom Kernel Function using the intensity profile\n",
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self, comblines):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.comblines = comblines\n",
    "        # Initialize k as a trainable parameter with the same size as C\n",
    "        self.k = nn.Parameter(torch.randn(comblines, dtype=torch.float, device='cpu'))\n",
    "\n",
    "    def forward(self, C, z=0.01):\n",
    "        return self.compute_intensity(self.k, C, z)\n",
    "\n",
    "    def compute_intensity(self, phases, coefficients, z):\n",
    "        N = self.comblines\n",
    "\n",
    "        # Prepend NaN to coefficients and phases\n",
    "        nan_tensor = torch.full((coefficients.size(0), 1), 0, dtype=coefficients.dtype, device=coefficients.device)\n",
    "        C = torch.cat((nan_tensor, coefficients), dim=1)\n",
    "\n",
    "        k = torch.cat((torch.tensor([0], dtype=phases.dtype, device=phases.device), phases))\n",
    "\n",
    "        # Preallocate intensity tensor\n",
    "        intensity = torch.zeros((coefficients.size(0), 2 * N + 1), dtype=torch.float, device=C.device)\n",
    "\n",
    "        # Use vectorized operations where possible\n",
    "        m_range = [torch.full((N-1, N-1), i, device=C.device) for i in torch.arange(2, 2 * N + 1)]\n",
    "        # Separate odd and even tensors based on the integer value inside the tensor\n",
    "        odd_m = [m for m in m_range if m[0, 0].item() % 2 == 1]\n",
    "        even_m = [m for m in m_range if m[0, 0].item() % 2 == 0]\n",
    "\n",
    "        js, ls = torch.meshgrid(torch.arange(1, N, device=C.device), torch.arange(1, N, device=C.device), indexing='ij')\n",
    "        for m in odd_m:\n",
    "\n",
    "            valid_indices = (0 < m - js) & (m - js <= N) & (0 < m - ls) & (m - ls <= N)\n",
    "\n",
    "            j, l, m = js[valid_indices], ls[valid_indices], m[valid_indices]\n",
    "\n",
    "            term = 4 * C[:, j] * C[:, m - j] * C[:, l] * C[:, m - l] * torch.cos((k[j] + k[m - j] - k[l] - k[m - l]) * z)\n",
    "            intensity[:, m[0]] = term.sum(dim=1)\n",
    "            #torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")\n",
    "\n",
    "        for m in even_m:\n",
    "            if m[0, 0] == 2 or m[0, 0] == 2 * N:\n",
    "                intensity[:, m[0, 0]] = C[:, m[0, 0] // 2] ** 4\n",
    "            else:\n",
    "                valid_indices = (0 < m - js) & (m - js <= N) & (0 < m - ls) & (m - ls <= N)\n",
    "\n",
    "                j, l, m = js[valid_indices], ls[valid_indices], m[valid_indices]\n",
    "\n",
    "                exp_term = torch.exp(1j * (k[j] + k[m - j]) * z)\n",
    "                middle_term = C[:, m // 2] ** 2 * torch.exp(1j * 2 * k[m // 2] * z)\n",
    "\n",
    "                term1 = (2 * C[:, j] * C[:, m - j] * exp_term + middle_term).sum(dim=1)\n",
    "                term2 = (2 * C[:, l] * C[:, m - l] * exp_term.conj() + middle_term.conj()).sum(dim=1)\n",
    "\n",
    "                intensity[:, m[0]] = (term1 * term2).real\n",
    "\n",
    "        return torch.abs(intensity[:, 2:2 * N + 1])/40000000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNWithCustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithCustomLayer, self).__init__()\n",
    "        self.flatten_size = 96 # Adjusted size after concatenation\n",
    "        self.custom_layer = CustomLayer(comblines=self.flatten_size)\n",
    "\n",
    "        # First convolutional layer: 32 filters, 3x3 kernel, input shape is (28, 28, 1)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # input channels = 1 (grayscale), output channels = 32\n",
    "        # Max pooling layer: 2x2 pool size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Fully connected layer 1: input size is 32 * 13 * 13 after conv + pool, output is 96\n",
    "        self.fc1 = nn.Linear(32 * 13 * 13, self.flatten_size)\n",
    "        # Add a Dropout layer with a dropout rate of 0.5\n",
    "        self.dropout = nn.Dropout(p=0.5)     \n",
    "        # Batch normalization for the fully connected layer\n",
    "        self.bn1 = nn.BatchNorm1d(2*self.flatten_size-1)\n",
    "        # Fully connected layer 2: output is 10 (for 10 classes)\n",
    "        self.fc2 = nn.Linear(2*self.flatten_size-1, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 32 * 13 * 13)      \n",
    "        x = self.custom_layer(self.fc1(x))\n",
    "        #x = self.bn1(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.307156\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 0.143584\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.332575\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.188778\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.339750\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.063313\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.191926\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.199433\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.058020\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.198895\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.129073\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.038347\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.538872\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.084102\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.009199\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.038366\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.074737\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.227730\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.049853\n",
      "\n",
      "Test set: Average loss: 0.1401, Accuracy: 9574/10000 (96%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.087506\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.182450\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.071981\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.082290\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.008817\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.134776\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.031896\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.012958\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.021262\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.029640\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.251339\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.018560\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.005099\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.052736\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.009355\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.208937\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.235356\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.006529\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.190729\n",
      "\n",
      "Test set: Average loss: 0.0738, Accuracy: 9779/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.011240\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.243958\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.074748\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.061458\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.030072\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.014892\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.003237\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.014749\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.078646\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.062869\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.050632\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.016399\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.004596\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.008922\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.021708\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.066168\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.031409\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.001812\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.104023\n",
      "\n",
      "Test set: Average loss: 0.0503, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.007482\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.320937\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.040715\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.005534\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.128340\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.008358\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.006403\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.001628\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.000797\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.018962\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.027719\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.211962\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.016329\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.000894\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.011497\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.000993\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.019622\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.048568\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.007841\n",
      "\n",
      "Test set: Average loss: 0.0576, Accuracy: 9846/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.016050\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.005507\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.127753\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.048723\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.002122\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.001827\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.093215\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.000874\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.002017\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.003022\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.001492\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.000755\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.043940\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.019948\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.148652\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.005304\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.168594\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.003755\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.017276\n",
      "\n",
      "Test set: Average loss: 0.0658, Accuracy: 9808/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.013293\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.000712\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000127\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.026664\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.001897\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.016265\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.006623\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.000039\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.094684\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.002825\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.011664\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.030422\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.056157\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.002922\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000266\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.005749\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.007360\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.001474\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.003841\n",
      "\n",
      "Test set: Average loss: 0.0713, Accuracy: 9839/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001424\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.012127\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000061\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.189749\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000030\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.075717\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.008670\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.003604\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.005408\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.000011\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.007599\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.082471\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.005340\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.000342\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000477\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.024006\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.010079\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.000902\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.005999\n",
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.007229\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.002060\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.406718\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.002754\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.013866\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000021\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.028696\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.002579\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.000118\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.014696\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.007879\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.011290\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.000760\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.014162\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.000008\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000450\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.001659\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.008514\n",
      "\n",
      "Test set: Average loss: 0.0697, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000126\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.000101\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000101\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.009710\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000641\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.000180\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.001121\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.000088\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000081\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.000155\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000158\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.009666\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000655\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.000377\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000619\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.025299\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.001617\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.033120\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.005779\n",
      "\n",
      "Test set: Average loss: 0.0749, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.197074\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.001289\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000009\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000026\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.001117\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.001055\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000192\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.001004\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.040883\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.003371\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.000341\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.005205\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.002755\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000395\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.008631\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000428\n",
      "\n",
      "Test set: Average loss: 0.0590, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    # Save checkpoint after each epoch (optional)\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    torch.save(checkpoint, f'./checkpoints_PhysicalNN/model_checkpointM{epoch}.pth')\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "\n",
    "model = CNNWithCustomLayer()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "checkpoint_file = './checkpoints_PhysicalNN/model_checkpoint10.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "\n",
    "    # Restore the model, optimizer, and epoch\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    running_loss = checkpoint['loss']\n",
    "\n",
    "    # If using GPU, ensure the model and optimizer are on the correct device\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Checkpoint loaded. Resuming training from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "    start_epoch = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(start_epoch, start_epoch + num_epochs):  # Adjust the range as needed\n",
    "    train(model, device, trainloader, optimizer, epoch)\n",
    "    test(model, device, testloader)\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalop\\AppData\\Local\\Temp\\ipykernel_35060\\1435961853.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('./checkpoints_PhysicalNN/model_checkpointM5.pth')  # Load the checkpoint\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Step 1: Load the image and preprocess it\n",
    "image = Image.open('./individual_test_images/ocho.png')\n",
    "image_gray = image.convert('L')\n",
    "image_resized = image_gray.resize((28, 28))\n",
    "\n",
    "# Convert the image to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(image_resized)\n",
    "\n",
    "# Add a batch dimension (required by the model)\n",
    "image_tensor = image_tensor.unsqueeze(0)  # Shape: [1, 1, 28, 28]\n",
    "\n",
    "# Step 2: Load the model and put it in evaluation mode\n",
    "model = CNNWithCustomLayer()\n",
    "checkpoint = torch.load('./checkpoints_PhysicalNN/model_checkpointM5.pth')  # Load the checkpoint\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Forward the image through the model\n",
    "with torch.no_grad():  # No need to track gradients for inference\n",
    "    output = model(image_tensor)\n",
    "\n",
    "# Step 4: Interpret the output\n",
    "predicted_class = output.argmax(dim=1, keepdim=True)  # Get the predicted class index\n",
    "print(f'Predicted Class: {predicted_class.item()}')\n",
    "\n",
    "# Step 5: Visualize the image (optional)\n",
    "plt.imshow(image_tensor.squeeze().numpy(), cmap='gray')\n",
    "plt.title(f'Predicted Class: {predicted_class.item()}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNWithCustomLayer1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithCustomLayer1, self).__init__()\n",
    "        self.flatten_size = 96 # Adjusted size after concatenation\n",
    "        self.custom_layer = CustomLayer(comblines=self.flatten_size)\n",
    "\n",
    "        # First convolutional layer: 32 filters, 3x3 kernel, input shape is (28, 28, 1)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # input channels = 1 (grayscale), output channels = 32\n",
    "        # Max pooling layer: 2x2 pool size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Fully connected layer 1: input size is 32 * 13 * 13 after conv + pool, output is 96\n",
    "        self.fc1 = nn.Linear(32 * 13 * 13, self.flatten_size)\n",
    "        # Add a Dropout layer with a dropout rate of 0.5\n",
    "        self.dropout = nn.Dropout(p=0.5)     \n",
    "        # Batch normalization for the fully connected layer\n",
    "        self.bn1 = nn.BatchNorm1d(self.flatten_size)\n",
    "        # Fully connected layer 2: output is 10 (for 10 classes)\n",
    "        self.fc2 = nn.Linear(self.flatten_size, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 32 * 13 * 13)      \n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.bn1(x)\n",
    "        #x = self.dropout(x)        \n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.526127\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 0.481292\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.227462\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.288296\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.202665\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.155661\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.338388\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.068519\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.046081\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.155011\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.153032\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.045591\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.056686\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.072837\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.033080\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.107930\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.095552\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.278568\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.282051\n",
      "\n",
      "Test set: Average loss: 0.0773, Accuracy: 9776/10000 (98%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.039486\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.035895\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.014077\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.141043\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.014173\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.016560\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.030613\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.093022\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.019113\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.066774\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.050493\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.026487\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.105500\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.023194\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.086304\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.017593\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.068522\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.024329\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.015433\n",
      "\n",
      "Test set: Average loss: 0.0660, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.108182\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.082835\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.005218\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.039792\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.138589\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.010855\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.043968\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.004203\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.039306\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.012679\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.047765\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.059231\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.039560\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.084215\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.005553\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.018748\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.020148\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.034061\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.001312\n",
      "\n",
      "Test set: Average loss: 0.0622, Accuracy: 9817/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.035732\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.025476\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.013247\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.008137\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001737\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.051760\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.111042\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.007516\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.016960\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.018680\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.005915\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.070147\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.001957\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.070041\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.033408\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.018820\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.068580\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.106618\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.004185\n",
      "\n",
      "Test set: Average loss: 0.0545, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.003147\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.026857\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000963\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.001848\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.002603\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.021529\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.020872\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.012480\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.009409\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.003798\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.027816\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.002150\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.038875\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.003242\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.012374\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.002221\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.019268\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.048977\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.107666\n",
      "\n",
      "Test set: Average loss: 0.0486, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004643\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.003366\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.003576\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.025564\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.112753\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.098120\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.038916\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.000997\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.004221\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.001531\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.066434\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.012272\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.051074\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.000699\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.024390\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.004747\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.005477\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.043526\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.002416\n",
      "\n",
      "Test set: Average loss: 0.0525, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.003238\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.006457\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.013430\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.001362\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.002538\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.017883\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.004486\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.000248\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.003484\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.155438\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000504\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.002037\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.003271\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.004252\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000704\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.079878\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000619\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.000419\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.021481\n",
      "\n",
      "Test set: Average loss: 0.0504, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.083266\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.001944\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.008057\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.001566\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.008783\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.002007\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000147\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.000915\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.001695\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.001790\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.004001\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.001295\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001483\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.000446\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.004835\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.001611\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000365\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.023570\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.062446\n",
      "\n",
      "Test set: Average loss: 0.0505, Accuracy: 9870/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.027037\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.000223\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.006297\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.009061\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.019246\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.028446\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.003524\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.014349\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000106\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.000443\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.002059\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.000149\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000088\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.003034\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000395\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.004051\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.001760\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.004575\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.002385\n",
      "\n",
      "Test set: Average loss: 0.0538, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002822\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.003870\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000732\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.003479\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.002695\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.001171\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.003483\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.002464\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.001461\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.002963\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.003350\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.016788\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.007820\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.002514\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000394\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.002418\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000387\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.126713\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.040080\n",
      "\n",
      "Test set: Average loss: 0.0498, Accuracy: 9867/10000 (99%)\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    # Save checkpoint after each epoch (optional)\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    torch.save(checkpoint, f'./checkpoints_PhysicalNN/model_checkpointM{epoch}.pth')\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "\n",
    "model = CNNWithCustomLayer1()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "checkpoint_file = './checkpoints_PhysicalNN/model_checkpoint10.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "\n",
    "    # Restore the model, optimizer, and epoch\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    running_loss = checkpoint['loss']\n",
    "\n",
    "    # If using GPU, ensure the model and optimizer are on the correct device\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Checkpoint loaded. Resuming training from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "    start_epoch = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(start_epoch, start_epoch + num_epochs):  # Adjust the range as needed\n",
    "    train(model, device, trainloader, optimizer, epoch)\n",
    "    test(model, device, testloader)\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalop\\AppData\\Local\\Temp\\ipykernel_9048\\1907311431.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('./checkpoints_PhysicalNN/model_checkpointM9.pth')  # Load the checkpoint\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Step 1: Load the image and preprocess it\n",
    "image = Image.open('./individual_test_images/seisd.png')\n",
    "image_gray = image.convert('L')\n",
    "image_resized = image_gray.resize((28, 28))\n",
    "\n",
    "# Convert the image to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(image_resized)\n",
    "\n",
    "# Add a batch dimension (required by the model)\n",
    "image_tensor = image_tensor.unsqueeze(0)  # Shape: [1, 1, 28, 28]\n",
    "\n",
    "# Step 2: Load the model and put it in evaluation mode\n",
    "model = CNNWithCustomLayer1()\n",
    "checkpoint = torch.load('./checkpoints_PhysicalNN/model_checkpointM9.pth')  # Load the checkpoint\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Forward the image through the model\n",
    "with torch.no_grad():  # No need to track gradients for inference\n",
    "    output = model(image_tensor)\n",
    "\n",
    "# Step 4: Interpret the output\n",
    "predicted_class = output.argmax(dim=1, keepdim=True)  # Get the predicted class index\n",
    "print(f'Predicted Class: {predicted_class.item()}')\n",
    "\n",
    "# Step 5: Visualize the image (optional)\n",
    "plt.imshow(image_tensor.squeeze().numpy(), cmap='gray')\n",
    "plt.title(f'Predicted Class: {predicted_class.item()}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
